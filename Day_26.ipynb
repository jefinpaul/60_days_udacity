{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day 26.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUVGpFRbjtfd",
        "colab_type": "code",
        "outputId": "e6184ae5-e53d-45ac-f4d1-04f740a9cb20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "#Reviewing to train a network using back propogation\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,),)])\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data',download= True,train = True,transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size = 64,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 9178025.48it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 140011.95it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2320375.30it/s]                            \n",
            "8192it [00:00, 54403.09it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hMsc09kyi2p",
        "colab_type": "code",
        "outputId": "7e4419b3-8035-4fcf-9ed0-c1ecbefa5bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logps = model(images)\n",
        "\n",
        "loss = criterion(logps, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3530, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmjWKBn99GHK",
        "colab_type": "code",
        "outputId": "c16ca0fa-df66-4641-91bf-666e5483dd6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Random\n",
        "x = torch.randn(2,2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.3795,  1.3426],\n",
            "        [ 0.4220, -1.1301]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd2DSkT-U2cR",
        "colab_type": "code",
        "outputId": "d2ef5b56-f83f-4a18-e2a2-e19ccb3a192a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#x squared\n",
        "print(x**2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.9030, 1.8025],\n",
            "        [0.1781, 1.2771]], grad_fn=<PowBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7vJHlI0U6EW",
        "colab_type": "code",
        "outputId": "2dbc7259-5320-4d7e-c384-bc63e4f17eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6AKePuRVRfW",
        "colab_type": "code",
        "outputId": "82567523-ba73-4a82-ab70-00d4c58b9a8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "y=x**2\n",
        "z=y.mean()\n",
        "z.backward()\n",
        "print(x.grad)\n",
        "print(x/2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.6897,  0.6713],\n",
            "        [ 0.2110, -0.5650]])\n",
            "tensor([[ 0.6897,  0.6713],\n",
            "        [ 0.2110, -0.5650]], grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d6v15iLVpq8",
        "colab_type": "code",
        "outputId": "4204d4e6-e94f-4ffb-be70-be4ad6f4d59f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logps = model(images)\n",
        "loss = criterion(logps, labels)\n",
        "\n",
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[-0.0006, -0.0006, -0.0006,  ..., -0.0006, -0.0006, -0.0006],\n",
            "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
            "        [-0.0026, -0.0026, -0.0026,  ..., -0.0026, -0.0026, -0.0026],\n",
            "        ...,\n",
            "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
            "        [-0.0011, -0.0011, -0.0011,  ..., -0.0011, -0.0011, -0.0011],\n",
            "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL6WSsliZVeC",
        "colab_type": "code",
        "outputId": "1385f22e-c650-4d81-ad05-1cd162c0b7f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "from torch import optim\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "print('Initial weights - ', model[0].weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(64, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model[0].weight.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[ 0.0271,  0.0158,  0.0024,  ..., -0.0333,  0.0087, -0.0096],\n",
            "        [-0.0246, -0.0248, -0.0027,  ..., -0.0176,  0.0072,  0.0261],\n",
            "        [-0.0320,  0.0339, -0.0243,  ..., -0.0271, -0.0033,  0.0218],\n",
            "        ...,\n",
            "        [-0.0266, -0.0341, -0.0220,  ...,  0.0158, -0.0320,  0.0100],\n",
            "        [-0.0338, -0.0178, -0.0055,  ..., -0.0037, -0.0232,  0.0161],\n",
            "        [-0.0138,  0.0285, -0.0178,  ..., -0.0044,  0.0221,  0.0094]],\n",
            "       requires_grad=True)\n",
            "Gradient - tensor([[ 0.0004,  0.0004,  0.0004,  ...,  0.0004,  0.0004,  0.0004],\n",
            "        [-0.0026, -0.0026, -0.0026,  ..., -0.0026, -0.0026, -0.0026],\n",
            "        [-0.0038, -0.0038, -0.0038,  ..., -0.0038, -0.0038, -0.0038],\n",
            "        ...,\n",
            "        [-0.0012, -0.0012, -0.0012,  ..., -0.0012, -0.0012, -0.0012],\n",
            "        [-0.0021, -0.0021, -0.0021,  ..., -0.0021, -0.0021, -0.0021],\n",
            "        [-0.0033, -0.0033, -0.0033,  ..., -0.0033, -0.0033, -0.0033]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi5GwaqJZZbP",
        "colab_type": "code",
        "outputId": "23484f7e-569a-4e16-f2bb-5e55d14a6c8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[ 0.0271,  0.0158,  0.0024,  ..., -0.0333,  0.0087, -0.0096],\n",
            "        [-0.0245, -0.0248, -0.0026,  ..., -0.0176,  0.0072,  0.0261],\n",
            "        [-0.0319,  0.0340, -0.0243,  ..., -0.0270, -0.0032,  0.0218],\n",
            "        ...,\n",
            "        [-0.0266, -0.0341, -0.0220,  ...,  0.0158, -0.0320,  0.0100],\n",
            "        [-0.0338, -0.0178, -0.0055,  ..., -0.0037, -0.0232,  0.0161],\n",
            "        [-0.0138,  0.0286, -0.0178,  ..., -0.0043,  0.0222,  0.0094]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ5h31RBcb1y",
        "colab_type": "code",
        "outputId": "96135949-f314-404e-dfcf-4b8dde265943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # TODO: Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 1.8837218818379873\n",
            "Training loss: 0.8486385862392657\n",
            "Training loss: 0.5250064662016277\n",
            "Training loss: 0.4319421619589903\n",
            "Training loss: 0.3877468932348528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N73zFeL9d7cd",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def test_network(net, trainloader):\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # Create Variables for the inputs and targets\n",
        "    inputs = Variable(images)\n",
        "    targets = Variable(images)\n",
        "\n",
        "    # Clear the gradients from all Variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass, then backward pass, then update weights\n",
        "    output = net.forward(inputs)\n",
        "    loss = criterion(output, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def view_recon(img, recon):\n",
        "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
        "        reconstruction also a PyTorch Tensor\n",
        "    '''\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
        "    axes[0].imshow(img.numpy().squeeze())\n",
        "    axes[1].imshow(recon.data.numpy().squeeze())\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box-forced')\n",
        "\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysDu7dKSd9_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "3d8f9b18-af6c-4a16-e379-4fcb0b8c7471"
      },
      "source": [
        "import helper\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADsCAYAAAAhDDIOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpZDCGtseDUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}