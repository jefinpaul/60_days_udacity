{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss and Autograd together\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 2.8815e-03,  2.8815e-03,  2.8815e-03,  ...,  2.8815e-03,\n",
      "          2.8815e-03,  2.8815e-03],\n",
      "        [-9.6081e-05, -9.6081e-05, -9.6081e-05,  ..., -9.6081e-05,\n",
      "         -9.6081e-05, -9.6081e-05],\n",
      "        [ 1.2010e-03,  1.2010e-03,  1.2010e-03,  ...,  1.2010e-03,\n",
      "          1.2010e-03,  1.2010e-03],\n",
      "        ...,\n",
      "        [-1.6559e-03, -1.6559e-03, -1.6559e-03,  ..., -1.6559e-03,\n",
      "         -1.6559e-03, -1.6559e-03],\n",
      "        [ 5.1427e-05,  5.1427e-05,  5.1427e-05,  ...,  5.1427e-05,\n",
      "          5.1427e-05,  5.1427e-05],\n",
      "        [ 2.3636e-03,  2.3636e-03,  2.3636e-03,  ...,  2.3636e-03,\n",
      "          2.3636e-03,  2.3636e-03]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stochastic gradient descent with optim.SGD\n",
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[-0.0113, -0.0258,  0.0286,  ...,  0.0105, -0.0291,  0.0215],\n",
      "        [ 0.0150,  0.0281,  0.0197,  ...,  0.0039, -0.0038, -0.0109],\n",
      "        [ 0.0140, -0.0019, -0.0276,  ...,  0.0070,  0.0133, -0.0243],\n",
      "        ...,\n",
      "        [ 0.0010,  0.0323,  0.0280,  ..., -0.0047, -0.0174,  0.0230],\n",
      "        [ 0.0228,  0.0243,  0.0121,  ...,  0.0153, -0.0303,  0.0176],\n",
      "        [ 0.0124,  0.0019, -0.0081,  ..., -0.0214, -0.0100, -0.0207]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[ 6.0185e-04,  6.0185e-04,  6.0185e-04,  ...,  6.0185e-04,\n",
      "          6.0185e-04,  6.0185e-04],\n",
      "        [-1.1244e-03, -1.1244e-03, -1.1244e-03,  ..., -1.1244e-03,\n",
      "         -1.1244e-03, -1.1244e-03],\n",
      "        [-1.1488e-05, -1.1488e-05, -1.1488e-05,  ..., -1.1488e-05,\n",
      "         -1.1488e-05, -1.1488e-05],\n",
      "        ...,\n",
      "        [ 1.7371e-03,  1.7371e-03,  1.7371e-03,  ...,  1.7371e-03,\n",
      "          1.7371e-03,  1.7371e-03],\n",
      "        [ 1.0028e-03,  1.0028e-03,  1.0028e-03,  ...,  1.0028e-03,\n",
      "          1.0028e-03,  1.0028e-03],\n",
      "        [-3.3469e-03, -3.3469e-03, -3.3469e-03,  ..., -3.3469e-03,\n",
      "         -3.3469e-03, -3.3469e-03]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[-0.0113, -0.0258,  0.0286,  ...,  0.0105, -0.0291,  0.0215],\n",
      "        [ 0.0150,  0.0281,  0.0197,  ...,  0.0039, -0.0037, -0.0109],\n",
      "        [ 0.0140, -0.0019, -0.0276,  ...,  0.0070,  0.0133, -0.0243],\n",
      "        ...,\n",
      "        [ 0.0010,  0.0323,  0.0280,  ..., -0.0047, -0.0174,  0.0230],\n",
      "        [ 0.0228,  0.0242,  0.0121,  ...,  0.0153, -0.0303,  0.0176],\n",
      "        [ 0.0124,  0.0019, -0.0081,  ..., -0.0213, -0.0100, -0.0207]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.016396059537493\n",
      "Training loss: 0.947768965096616\n",
      "Training loss: 0.5444609115499932\n",
      "Training loss: 0.43864738520210994\n",
      "Training loss: 0.39137791287797347\n"
     ]
    }
   ],
   "source": [
    "#put this algorithm into a loop\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
